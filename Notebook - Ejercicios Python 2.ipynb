{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0. Dada una cadena que contiene una frase, determina si es un pal√≠ndromo (si los espacios en blanco no son relevantes).</h3> Un pal√≠ndromo se lee igual de adelante hacia atr√°s que de atr√°s hacia adelante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it palindrome? True\n"
     ]
    }
   ],
   "source": [
    "data = 'dabale arroz a la zorra el abad'\n",
    "\n",
    "print('Is it palindrome?', is_palindrome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Dada una cadena que contiene un c√≥digo binario, encuentra la longitud de la\n",
    "secuencia m√°s larga de unos consecutivos.</h3>\n",
    "<h4>1.1 Indica la posici√≥n donde comienza la\n",
    "secuencia m√°s larga de unos consecutivos en la cadena dada.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = '1001010101111101010101010111100101010011111110001001110010'\n",
    "\n",
    "print('The longest burst of ones has length:', max_burst_len) # should print 7\n",
    "print('was found at position:', max_burst_index)) # should print 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Dada una cadena de letras, intercambia las dos primeras letras <u>si no est√°n en orden alfab√©tico</u></h3>\n",
    "<h4>2.1 Haz lo mismo para todos los pares de letras consecutivas en la cadena</h4>\n",
    "<h4>2.2 Repite este proceso hasta que toda la cadena est√© ordenada alfab√©ticamente</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = 'abzefyhijklmnuoptq'\n",
    "\n",
    "print(new_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Dada una cadena de n√∫meros enteros separados por comas, calcula la media</h3>\n",
    "<h4>3.1 Pon especial atenci√≥n en identificar correctamente los n√∫meros enteros</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = '100,-200,100,40' \n",
    "\n",
    "print('The average is:', average)) # should print 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Dada una cadena con algunas palabras separadas por espacios, genera una cadena similar pero sin palabras repetidas.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = 'their father followed their track for many many hours until the sunset'\n",
    "\n",
    "print(result) # their father followed track for many hours until the sunset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Dado un archivo de texto, contar la aparici√≥n de cada palabra.</h3>\n",
    "<h4>5.1 Leer el contenido del archivo y procesarlo para identificar las palabras.</h4>\n",
    "<h4>5.2 Ignorar may√∫sculas y signos de puntuaci√≥n para considerar palabras equivalentes.</h4>\n",
    "<h4>5.3 Generar un diccionario donde las claves sean las palabras y los valores el n√∫mero de veces que aparecen en el texto.</h4>\n",
    "<h4>5.4 Mostrar las palabras ordenadas de mayor a menor frecuencia de aparici√≥n.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "este: 4\n",
      "de: 4\n",
      "texto: 4\n",
      "palabras: 4\n",
      "repetidas: 4\n",
      "es: 2\n",
      "un: 2\n",
      "ejemplo: 2\n",
      "archivo: 2\n",
      "tiene: 2\n",
      "las: 2\n",
      "ayudan: 2\n",
      "a: 2\n",
      "probar: 2\n",
      "el: 2\n",
      "c√≥digo: 2\n",
      "correctamente: 2\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def contar_palabras(archivo):\n",
    "    \"\"\"\n",
    "    Lee un archivo de texto y cuenta la aparici√≥n de cada palabra.\n",
    "    \"\"\"\n",
    "    frecuencia_palabras ={}\n",
    "    try:\n",
    "        with open(archivo, \"r\", encoding=\"utf-8\") as f:\n",
    "            texto = f.read().lower()  # Convertir todo a min√∫sculas para evitar duplicados\n",
    "        \n",
    "        # Eliminar puntuaci√≥n\n",
    "        texto = texto.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        \n",
    "        # Dividir en palabras\n",
    "        palabras = texto.split()\n",
    "        \n",
    "        # Contar ocurrencias\n",
    "        frecuencia_palabras = {}\n",
    "\n",
    "        # Aqui completa tu c√≥digo ...\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: El archivo no existe.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurri√≥ un error: {e}\")\n",
    "\n",
    "    return frecuencia_palabras\n",
    "\n",
    "def imprimirDiccionario(frecuencia_palabras):\n",
    "    # Mostrar resultados ordenados por frecuencia\n",
    "    for palabra, frecuencia in frecuencia_palabras.most_common():\n",
    "        print(f\"{palabra}: {frecuencia}\")\n",
    "        \n",
    "# Ejemplo de uso\n",
    "archivo = \"texto_test.txt\"  # Nombre del archivo de texto\n",
    "#archivo = \"texto_cars.txt\"  # Nombre del archivo de texto\n",
    "#archivo = \"texto_ibai.txt\"  # Nombre del archivo de texto\n",
    "freq = contar_palabras(archivo)\n",
    "imprimirDiccionario(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prueba experimental.\n",
    "\n",
    "En el texto anterior, vemos que no podemos sacar mucha informaci√≥n porque sobre todo se repiten conjunciones, determinantes etc. Si te ha sobrado tiempo haciendo los ejercicios, vamos a jugar un rato üòà.</h3>\n",
    "\n",
    "Ahora vamos a probar a instalar una librer√≠a para analizar el lenguaje. Ejecuta el siguiente bloque para instalar spacy y su modelo de lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy ya est√° instalado.\n",
      "El modelo 'es_core_news_sm' no est√° instalado. Instalando...\n",
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n",
      "Modelo 'es_core_news_sm' instalado correctamente.\n",
      "Verificaci√≥n completa: spaCy y el modelo en espa√±ol est√°n listos.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def instalar_spacy_y_modelo():\n",
    "    try:\n",
    "        import spacy\n",
    "        print(\"spaCy ya est√° instalado.\")\n",
    "    except ImportError:\n",
    "        print(\"spaCy no est√° instalado. Instalando...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"spacy\"])\n",
    "        print(\"spaCy instalado correctamente.\")\n",
    "\n",
    "    # Intentar cargar el modelo de espa√±ol\n",
    "    try:\n",
    "        import spacy\n",
    "        spacy.load(\"es_core_news_sm\")\n",
    "        print(\"El modelo 'es_core_news_sm' ya est√° instalado.\")\n",
    "    except OSError:\n",
    "        print(\"El modelo 'es_core_news_sm' no est√° instalado. Instalando...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"es_core_news_sm\"])\n",
    "        print(\"Modelo 'es_core_news_sm' instalado correctamente.\")\n",
    "\n",
    "        # Verificar instalaci√≥n nuevamente\n",
    "        try:\n",
    "            spacy.load(\"es_core_news_sm\")\n",
    "            print(\"Verificaci√≥n completa: spaCy y el modelo en espa√±ol est√°n listos.\")\n",
    "        except OSError:\n",
    "            print(\"Error: El modelo no pudo ser cargado despu√©s de la instalaci√≥n.\")\n",
    "\n",
    "# Ejecutar la instalaci√≥n\n",
    "instalar_spacy_y_modelo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ahora ya deber√≠a estar instalado, vamos a ver que funciona ...</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Verbos encontrados: ['correr', 'jugando', 'comer']\n",
      "Sustantivos encontrados: ['perro']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Cargar el modelo en espa√±ol de spaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def es_verbo(palabra):\n",
    "    doc = nlp(palabra)\n",
    "    return any(token.pos_ == \"VERB\" for token in doc)\n",
    "\n",
    "def es_sustantivo(palabra):\n",
    "    \"\"\"\n",
    "    Analiza si una palabra es un sustantivo com√∫n.\n",
    "    \"\"\"\n",
    "    doc = nlp(palabra)\n",
    "    return any(token.pos_ == \"NOUN\" for token in doc)  # \"NOUN\" indica sustantivos comunes\n",
    "\n",
    "# Ejemplo\n",
    "print(\"Starting...\")\n",
    "palabras = [\"correr\", \"r√°pido\", \"jugando\", \"feliz\", \"comer\", \"perro\"]\n",
    "verbos = [palabra for palabra in palabras if es_verbo(palabra)]\n",
    "sustantivos = [palabra for palabra in palabras if es_sustantivo(palabra)]\n",
    "print(\"Verbos encontrados:\", verbos)\n",
    "print(\"Sustantivos encontrados:\", sustantivos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Si encuentra los verbos y sustantivos, ahora vuelve a analizar el texto de Ibai, y analiza cuales son los verbos y sustantivos m√°s utilizados </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m archivo \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtexto_ibai.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Nombre del archivo de texto\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#archivo = \"texto_cars.txt\"  # Nombre del archivo de texto\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#archivo = \"texto_ibai.txt\"  # Nombre del archivo de texto\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m contar_verbos_y_nombres(archivo)\n",
      "Cell \u001b[0;32mIn[91], line 22\u001b[0m, in \u001b[0;36mcontar_verbos_y_nombres\u001b[0;34m(archivo_entrada)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Iterar sobre cada palabra y contar solo sustantivos y verbos\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m palabras:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m es_sustantivo(token) \u001b[38;5;129;01mor\u001b[39;00m es_verbo(token):\n\u001b[1;32m     23\u001b[0m         palabra \u001b[38;5;241m=\u001b[39m token\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# Comprobar si la palabra ya est√° en el diccionario\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[55], line 14\u001b[0m, in \u001b[0;36mes_sustantivo\u001b[0;34m(palabra)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mes_sustantivo\u001b[39m(palabra):\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Analiza si una palabra es un sustantivo com√∫n.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(palabra)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOUN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/spacy/language.py:1052\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1052\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/spacy/pipeline/tok2vec.py:126\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[0;32m--> 126\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(docs)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     75\u001b[0m lengths \u001b[38;5;241m=\u001b[39m NUMPY_OPS\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[1;32m     76\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[0;32m---> 77\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m layer(Xf, is_train)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n\u001b[1;32m     80\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[0;32m---> 41\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](X, is_train)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[1;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/layernorm.py:24\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, InT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[InT, Callable]:\n\u001b[0;32m---> 24\u001b[0m     N, mu, var \u001b[38;5;241m=\u001b[39m _get_moments(model\u001b[38;5;241m.\u001b[39mops, X)\n\u001b[1;32m     25\u001b[0m     Xhat \u001b[38;5;241m=\u001b[39m (X \u001b[38;5;241m-\u001b[39m mu) \u001b[38;5;241m*\u001b[39m var \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m     26\u001b[0m     Y, backprop_rescale \u001b[38;5;241m=\u001b[39m _begin_update_scale_shift(model, Xhat)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/thinc/layers/layernorm.py:75\u001b[0m, in \u001b[0;36m_get_moments\u001b[0;34m(ops, X)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_moments\u001b[39m(ops: Ops, X: Floats2d) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Floats2d, Floats2d, Floats2d]:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# TODO: Do mean methods\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     mu: Floats2d \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 75\u001b[0m     var: Floats2d \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mvar(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-08\u001b[39m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Floats2d, ops\u001b[38;5;241m.\u001b[39masarray_f([X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]])), mu, var\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_methods.py:162\u001b[0m, in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    160\u001b[0m     div \u001b[38;5;241m=\u001b[39m rcount\u001b[38;5;241m.\u001b[39mreshape(arrmean\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrmean, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n\u001b[1;32m    163\u001b[0m         arrmean \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(arrmean, div, out\u001b[38;5;241m=\u001b[39marrmean,\n\u001b[1;32m    164\u001b[0m                                  casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(arrmean, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_ufunc_config.py:466\u001b[0m, in \u001b[0;36m_no_nep50_warning\u001b[0;34m()\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     NO_NEP50_WARNING\u001b[38;5;241m.\u001b[39mreset(token)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def contar_verbos_y_nombres(archivo_entrada):\n",
    "   \n",
    "\n",
    "archivo = \"texto_ibai.txt\"  # Nombre del archivo de texto\n",
    "#archivo = \"texto_cars.txt\"  # Nombre del archivo de texto\n",
    "#archivo = \"texto_ibai.txt\"  # Nombre del archivo de texto\n",
    "contar_verbos_y_nombres(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
